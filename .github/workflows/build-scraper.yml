name: Build and Deploy Scraper Docker Image

on:
    push:
        branches: [main]
        paths:
            - 'packages/scraping-worker/**'
            - 'packages/shared/**'
            - 'packages/db/**'
            - 'docker/scraper.Dockerfile'
    workflow_dispatch:

env:
    REGISTRY: docker.io
    DOCKER_BUILDKIT: 1

jobs:
    build-scraper:
        runs-on: ubuntu-latest
        steps:
            - name: Checkout code
              uses: actions/checkout@v4

            - name: Set up Docker Buildx
              uses: docker/setup-buildx-action@v3

            - name: Log in to Docker Hub
              if: github.event_name != 'pull_request'
              uses: docker/login-action@v3
              with:
                  registry: ${{ env.REGISTRY }}
                  username: ${{ secrets.DOCKER_HUB_USERNAME }}
                  password: ${{ secrets.DOCKER_HUB_ACCESS_TOKEN }}

            - name: Extract metadata
              id: meta
              uses: docker/metadata-action@v5
              with:
                  images: ${{ env.REGISTRY }}/${{ secrets.DOCKER_HUB_USERNAME }}/linkinvests-scraper
                  tags: |
                      type=sha
                      type=raw,value=latest

            - name: Build and push scraper Docker image
              uses: docker/build-push-action@v5
              with:
                  context: .
                  file: docker/scraper.Dockerfile
                  push: ${{ github.event_name != 'pull_request' }}
                  tags: ${{ steps.meta.outputs.tags }}
                  labels: ${{ steps.meta.outputs.labels }}
                  cache-from: type=gha
                  cache-to: type=gha,mode=max
                  platforms: linux/amd64
                  build-args: |
                      BUILDKIT_INLINE_CACHE=1
              timeout-minutes: 60